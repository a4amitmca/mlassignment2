{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0eccc95",
   "metadata": {},
   "source": [
    "# Heart Disease Classification â€” Training Notebook\n",
    "\n",
    "This notebook converts your existing `train.py` and `utils.py` into an interactive Jupyter workflow.\n",
    "\n",
    "**What you'll do:**\n",
    "1. Install dependencies\n",
    "2. Load the Heart Disease dataset (`data/heart.csv`)\n",
    "3. Build preprocessing (scale numeric, one-hot encode categorical)\n",
    "4. Train 6 models (LogReg, DecisionTree, kNN, GaussianNB, RandomForest, XGBoost)\n",
    "5. Evaluate & save artifacts to `models/`\n",
    "\n",
    "> **Note:** Place `heart.csv` from Kaggle (dataset: `fedesoriano/heart-failure-prediction`) into a local `data/` folder before running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b5832",
   "metadata": {},
   "source": [
    "## 1) Install / Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "326f824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If running in a fresh environment, uncomment to install xgboost\n",
    "# %pip install xgboost joblib scikit-learn pandas numpy matplotlib\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score, recall_score, f1_score,\n",
    "    matthews_corrcoef, classification_report, confusion_matrix\n",
    ")\n",
    "from joblib import dump\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except Exception as e:\n",
    "    XGBClassifier = None\n",
    "    print(\"xgboost not available. You can install it with: %pip install xgboost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e6a691",
   "metadata": {},
   "source": [
    "## 2) Configuration & Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fb50cb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(918, 12)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "TARGET_COL = 'HeartDisease'\n",
    "DATA_PATH = os.path.join('heart.csv')\n",
    "assert os.path.exists(DATA_PATH), f\"Dataset not found at {DATA_PATH}. Please download heart.csv from Kaggle and place it here.\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "assert TARGET_COL in df.columns, f\"Target column '{TARGET_COL}' not found. Columns: {df.columns.tolist()}\"\n",
    "\n",
    "# Quick peek\n",
    "display(df.head())\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22168f5d",
   "metadata": {},
   "source": [
    "## 3) Build preprocessing (mirrors `utils.py`)\n",
    "Automatically separate numeric/categorical features, scale numeric, one-hot encode categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9750abc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak']\n",
      "Categorical columns: ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Infer columns\n",
    "cols = list(df.columns)\n",
    "feature_cols = [c for c in cols if c != TARGET_COL]\n",
    "cat_cols = [c for c in feature_cols if df[c].dtype == 'object']\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "# Use dense output from OHE for broad compatibility\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', ohe, cat_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "print('Numeric columns:', num_cols)\n",
    "print('Categorical columns:', cat_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e5655",
   "metadata": {},
   "source": [
    "## 4) Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "487e459e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((734, 11), (184, 11))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948298a4",
   "metadata": {},
   "source": [
    "## 5) Define models and helper to build pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cac0f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'kNN': KNeighborsClassifier(n_neighbors=7),\n",
    "    'Naive Bayes (Gaussian)': GaussianNB(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "}\n",
    "if XGBClassifier is not None:\n",
    "    models['XGBoost'] = XGBClassifier(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=4,\n",
    "        subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,\n",
    "        random_state=42, n_jobs=-1, eval_metric='logloss'\n",
    "    )\n",
    "\n",
    "from sklearn.pipeline import Pipeline as SkPipeline\n",
    "\n",
    "def make_pipeline(model):\n",
    "    return SkPipeline(steps=[('pre', preprocessor), ('clf', model)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856d810e",
   "metadata": {},
   "source": [
    "## 6) Train, evaluate, and save artifacts to `models/`\n",
    "We compute Accuracy, ROC-AUC, Precision, Recall, F1, and MCC. Confusion matrices and classification reports are also saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "97e8724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Training kNN...\n",
      "Training Naive Bayes (Gaussian)...\n",
      "Training Random Forest...\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Model Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.950263</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.922330</td>\n",
       "      <td>0.823786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.933106</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.801841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.929938</td>\n",
       "      <td>0.871560</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>0.769383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes (Gaussian)</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.897561</td>\n",
       "      <td>0.768780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.928384</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.737976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>0.791009</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.582018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ML Model Name  Accuracy       AUC  Precision    Recall        F1  \\\n",
       "2                     kNN  0.913043  0.950263   0.913462  0.931373  0.922330   \n",
       "4           Random Forest  0.902174  0.933106   0.896226  0.931373  0.913462   \n",
       "0     Logistic Regression  0.885870  0.929938   0.871560  0.931373  0.900474   \n",
       "3  Naive Bayes (Gaussian)  0.885870  0.911765   0.893204  0.901961  0.897561   \n",
       "5                 XGBoost  0.869565  0.928384   0.897959  0.862745  0.880000   \n",
       "1           Decision Tree  0.793478  0.791009   0.813725  0.813725  0.813725   \n",
       "\n",
       "        MCC  \n",
       "2  0.823786  \n",
       "4  0.801841  \n",
       "0  0.769383  \n",
       "3  0.768780  \n",
       "5  0.737976  \n",
       "1  0.582018  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "records = []\n",
    "report_dir = 'models'\n",
    "os.makedirs(report_dir, exist_ok=True)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    pipe = make_pipeline(model)\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    if hasattr(pipe.named_steps['clf'], 'predict_proba'):\n",
    "        y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(pipe.named_steps['clf'], 'decision_function'):\n",
    "        y_prob = pipe.decision_function(X_test)\n",
    "    else:\n",
    "        y_prob = None\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else float('nan')\n",
    "\n",
    "    records.append({\n",
    "        'ML Model Name': name,\n",
    "        'Accuracy': acc,\n",
    "        'AUC': auc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1': f1,\n",
    "        'MCC': mcc,\n",
    "    })\n",
    "\n",
    "    safe_name = name.replace(' ', '_').replace('(', '').replace(')', '').replace('-', '')\n",
    "    dump(pipe, os.path.join(report_dir, f\"{safe_name}.pkl\"))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cr = classification_report(y_test, y_pred)\n",
    "    with open(os.path.join(report_dir, f\"{name}_report.txt\"), 'w') as f:\n",
    "       f.write(f\"Classification Report for {name}\")\n",
    "       f.write(cr)\n",
    "       f.write(\"Confusion Matrix:\")\n",
    "       f.write(np.array2string(cm))\n",
    "\n",
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame(records)\n",
    "metrics_df.to_csv(os.path.join(report_dir, 'metrics.csv'), index=False)\n",
    "metrics_df.sort_values('Accuracy', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b007fd4",
   "metadata": {},
   "source": [
    "## 7) (Optional) Update README.md with a metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fc70e2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md updated with metrics table.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "readme_path = 'README.md'\n",
    "\n",
    "# Both possible tag forms\n",
    "\n",
    "# Literal HTML comment tags\n",
    "\n",
    "# Literal HTML comment tags\n",
    "LITERAL_START = '<!--METRICS_TABLE_START-->'\n",
    "LITERAL_END   = '<!--METRICS_TABLE_END-->'\n",
    "\n",
    "# HTML-escaped versions (only if your README truly contains these)\n",
    "ESC_START = '&lt;!--METRICS_TABLE_START--&gt;'\n",
    "ESC_END   = '&lt;!--METRICS_TABLE_END--&gt;'\n",
    "\n",
    "\n",
    "def fmt_val(v):\n",
    "    \"\"\"Format numeric to 4 decimals; render NaN/None as '-'.\"\"\"\n",
    "    if v is None:\n",
    "        return '-'\n",
    "    try:\n",
    "        if isinstance(v, (int, float)) and not math.isnan(float(v)):\n",
    "            return f\"{float(v):.4f}\"\n",
    "        # float('nan') -> math.isnan catches above; strings pass through\n",
    "        return str(v)\n",
    "    except Exception:\n",
    "        return str(v)\n",
    "\n",
    "def build_metrics_table(df):\n",
    "    header = \"**ML Model Name** | **Accuracy** | **AUC** | **Precision** | **Recall** | **F1** | **MCC**\"\n",
    "    sep    = \"---|---|---|---|---|---|---\"\n",
    "    required = [\"ML Model Name\", \"Accuracy\", \"AUC\", \"Precision\", \"Recall\", \"F1\", \"MCC\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"metrics_df is missing columns: {missing}\")\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        rows.append(\n",
    "            f\"{r['ML Model Name']} | {fmt_val(r['Accuracy'])} | {fmt_val(r['AUC'])} | \"\n",
    "            f\"{fmt_val(r['Precision'])} | {fmt_val(r['Recall'])} | {fmt_val(r['F1'])} | {fmt_val(r['MCC'])}\"\n",
    "        )\n",
    "    return \"\\n\".join([header, sep] + rows) + \"\\n\"\n",
    "\n",
    "def detect_tag_form(text):\n",
    "    \"\"\"Return (start_tag, end_tag) if found, else (None, None).\"\"\"\n",
    "    # Prefer literal if both exist\n",
    "    if LITERAL_START in text and LITERAL_END in text:\n",
    "        return LITERAL_START, LITERAL_END\n",
    "    if ESC_START in text and ESC_END in text:\n",
    "        return ESC_START, ESC_END\n",
    "    return None, None\n",
    "\n",
    "def ensure_tags(text):\n",
    "    \"\"\"\n",
    "    Ensure tags exist; if absent, append literal tags at the end\n",
    "    and return updated text and the tag pair to use.\n",
    "    \"\"\"\n",
    "    s, e = detect_tag_form(text)\n",
    "    if s and e:\n",
    "        return text, s, e\n",
    "    # No tags found: append a block with literal tags\n",
    "    block = (\n",
    "        \"\\n\\n\"\n",
    "        + LITERAL_START + \"\\n\"\n",
    "        + \"<!-- Table will be injected here -->\\n\"\n",
    "        + LITERAL_END + \"\\n\"\n",
    "    )\n",
    "    return text.rstrip() + block, LITERAL_START, LITERAL_END\n",
    "\n",
    "if not os.path.exists(readme_path):\n",
    "    # If file doesn't exist, create it with literal tags\n",
    "    os.makedirs(os.path.dirname(readme_path), exist_ok=True)\n",
    "    with open(readme_path, 'w', encoding='utf-8', newline='\\n') as f:\n",
    "        f.write(\n",
    "            \"# Project Title\\n\\n\"\n",
    "            \"Some description.\\n\\n\"\n",
    "            f\"{LITERAL_START}\\n\"\n",
    "            \"<!-- Table will be injected here -->\\n\"\n",
    "            f\"{LITERAL_END}\\n\"\n",
    "        )\n",
    "\n",
    "# Normalize newlines to LF to avoid index mistakes\n",
    "with open(readme_path, 'r', encoding='utf-8') as f:\n",
    "    md = f.read().replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "\n",
    "# Ensure tags exist (insert if missing) and identify which pair to use\n",
    "md, START_TAG, END_TAG = ensure_tags(md)\n",
    "\n",
    "# Build the table (expects metrics_df in scope)\n",
    "md_table = build_metrics_table(metrics_df)\n",
    "\n",
    "# Inject between first matching pair\n",
    "start_idx = md.find(START_TAG)\n",
    "end_idx = md.find(END_TAG)\n",
    "\n",
    "if start_idx != -1 and end_idx != -1 and end_idx > start_idx:\n",
    "    before = md[:start_idx + len(START_TAG)]\n",
    "    after = md[end_idx:]\n",
    "    injection = \"\\n\" + md_table + \"\\n\"\n",
    "    new_md = before.rstrip() + \"\\n\" + injection + after.lstrip()\n",
    "    with open(readme_path, 'w', encoding='utf-8', newline='\\n') as f:\n",
    "        f.write(new_md)\n",
    "    print(\"README.md updated with metrics table.\")\n",
    "else:\n",
    "    # Should not happen due to ensure_tags, but keep a safeguard\n",
    "    print(\"Placeholder tags not found in README.md; skipping auto-update.\")\n",
    "LITERAL_END   = '<!--METRICS_TABLE_END-->'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
